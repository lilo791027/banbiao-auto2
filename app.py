import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from io import BytesIO
from datetime import datetime
import re
from itertools import cycle

# --------------------
# æ¨¡çµ„ 1ï¼šè§£é™¤åˆä½µå„²å­˜æ ¼ä¸¦å¡«å…¥åŸå€¼
# --------------------
def unmerge_and_fill(ws):
    for merged in list(ws.merged_cells.ranges):
        value = ws.cell(merged.min_row, merged.min_col).value
        ws.unmerge_cells(str(merged))
        for row in ws[merged.coord]:
            for cell in row:
                cell.value = value

# --------------------
# æ¨¡çµ„ 2ï¼šæ•´ç†ç­è¡¨è³‡æ–™
# --------------------
def consolidate_selected_sheets(wb, sheet_names):
    all_data = []
    for sheet_name in sheet_names:
        ws = wb[sheet_name]
        unmerge_and_fill(ws)
        clinic_name = str(ws.cell(row=1, column=1).value).strip()[:4] 
        max_row = ws.max_row
        max_col = ws.max_column
        for r in range(1, max_row + 1):
            for c in range(2, max_col + 1):
                cell_value = ws.cell(r, c).value
                if isinstance(cell_value, datetime):
                    date_val = cell_value
                    i = r + 3
                    while i <= max_row:
                        shift_type = str(ws.cell(i, c).value).strip()
                        if isinstance(ws.cell(i, c).value, datetime) or shift_type == "":
                            break
                        if shift_type in ["æ—©", "åˆ", "æ™š"]:
                            i += 1
                            while i <= max_row:
                                if isinstance(ws.cell(i, c).value, datetime):
                                    break
                                val = str(ws.cell(i, c).value).strip()
                                if val in ["æ—©", "åˆ", "æ™š"]:
                                    break
                                all_data.append([
                                    clinic_name,
                                    date_val.strftime("%Y/%m/%d"),
                                    shift_type,
                                    val
                                ])
                                i += 1
                            i -= 1
                        i += 1
    df = pd.DataFrame(all_data, columns=["è¨ºæ‰€", "æ—¥æœŸ", "ç­åˆ¥", "å§“å"])
    return df

# --------------------
# æ¨¡çµ„ 3ï¼šå»ºç«‹ç­åˆ¥åˆ†æè¡¨ (å«è·ç¨±è®€å–)
# --------------------
def create_shift_analysis(df_shift: pd.DataFrame, df_emp: pd.DataFrame, shift_map: dict) -> pd.DataFrame:
    df_shift = df_shift.copy()
    df_emp = df_emp.copy()
    # æ¸…æ´—æ¬„ä½åç¨±
    df_shift.columns = [str(c).strip() for c in df_shift.columns]
    df_emp.columns = [str(c).strip() for c in df_emp.columns]

    emp_dict = {}
    for _, row in df_emp.iterrows():
        name = str(row.get("å“¡å·¥å§“å", "")).strip()
        if name:
            emp_dict[name] = [
                str(row.get("å“¡å·¥ç·¨è™Ÿ", "")).strip(),
                str(row.get("æ‰€å±¬éƒ¨é–€", "")).strip(),
                str(row.get("è·ç¨±", "")).strip(), # é—œéµï¼šè®€å–è·ç¨±ï¼Œç”¨æ–¼ç¸½è¡¨å¡«è£œåˆ¤æ–·
                str(row.get("åˆ†é¡", "")).strip(),
                str(row.get("ç‰¹æ®Šæ—©ç­", "")).strip()
            ]

    shift_dict = {}
    for _, row in df_shift.iterrows():
        name = str(row.get("å§“å", "")).strip()
        clinic = str(row.get("è¨ºæ‰€", "")).strip()
        date_val = row.get("æ—¥æœŸ", "")
        shift_type = str(row.get("ç­åˆ¥", "")).strip()
        if not name or pd.isna(date_val):
            continue
        key = f"{name}|{date_val}|{clinic}"
        if key not in shift_dict:
            shift_dict[key] = set()
        shift_dict[key].add(shift_type)

    data_out = []
    for key, shifts in shift_dict.items():
        name, date_val, clinic = key.split("|")
        if name not in emp_dict:
            continue
        
        # çµ„åˆç­åˆ¥ï¼šæ’åºå¾Œå­—ä¸² (ä¾‹å¦‚ "æ—©åˆ")
        shift_parts = [s for s in ["æ—©", "åˆ", "æ™š"] if s in shifts]
        shift_type_for_code = "".join(sorted(shift_parts, key=lambda x: {"æ—©": 1, "åˆ": 2, "æ™š": 3}.get(x, 9)))

        emp_info = emp_dict.get(name, ["", "", "", "", ""])
        emp_id, emp_dept, emp_title, emp_category, emp_early_special = emp_info
        
        class_code = get_class_code(emp_category, emp_early_special, clinic, shift_type_for_code, shift_map)
        original_shift_type = shift_type_for_code

        data_out.append([clinic, emp_id, emp_dept, name, emp_title, date_val, original_shift_type, class_code])

    df_analysis = pd.DataFrame(
        data_out,
        columns=["è¨ºæ‰€", "å“¡å·¥ç·¨è™Ÿ", "æ‰€å±¬éƒ¨é–€", "å§“å", "è·ç¨±", "æ—¥æœŸ", "ç­åˆ¥", "ç­åˆ¥ä»£ç¢¼"]
    )

    invalid_names = ["None", "nan", "ç¾©è¨º", "å–®è¨º", "ç›¤é»", "é›»æ‰“"]
    df_analysis = df_analysis[~df_analysis["å§“å"].astype(str).str.strip().isin(invalid_names)].copy()
    return df_analysis

def get_class_code(emp_category, emp_early_special, clinic_name, shift_type, shift_map):
    """
    ç­åˆ¥ä»£ç¢¼è½‰æ›é‚è¼¯ï¼š
    1. ç‰¹æ®Šæ—©ç­ (æœ€é«˜å„ªå…ˆ)
    2. ä¸€èˆ¬å–®ä¸€æ—©ç­
    3. æ—©åˆæ™š -> å…¨å¤©ç­
    4. å…¶ä»–é è¨­
    """
    region = "ç«‹ä¸" if re.search(r"ç«‹ä¸", str(clinic_name), re.IGNORECASE) else "æ¿åœŸä¸­äº¬"
    is_early_special = str(emp_early_special).strip().lower() in ["æ˜¯", "true"]

    # 1. ç‰¹æ®Šæ—©ç­ç‰¹æ¬Š
    if is_early_special and "æ—©" in shift_type:
        if shift_type == "æ—©":
            return "ã€å“¡å·¥ã€‘ç´”æ—©ç­"
        elif shift_type == "æ—©åˆ":
            return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€åˆç­"
        elif shift_type == "æ—©æ™š":
            return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€æ™šç­"
        elif shift_type == "æ—©åˆæ™š":
            return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©åˆæ™šç­"
    
    # 2. ä¸€èˆ¬å–®ä¸€æ—©ç­
    if shift_type == "æ—©":
        if emp_category == "â˜…é†«å¸«â˜…":
            return "â˜…é†«å¸«â˜…æ—©ç­"
        elif emp_category == "â—‡ä¸»ç®¡â—‡":
            return "â—‡ä¸»ç®¡â—‡æ—©ç­"
        elif emp_category == "ã€å“¡å·¥ã€‘":
            return "ã€å“¡å·¥ã€‘æ—©ç­"

    # 3. æ—©åˆæ™š -> å…¨å¤©ç­
    if shift_type == "æ—©åˆæ™š":
        return f"{emp_category}{region}å…¨å¤©ç­"
    
    # 4. é è¨­é‚è¼¯
    base_shift = shift_map.get(shift_type)
    if base_shift is None:
        base_shift = shift_type
    
    if not str(base_shift).strip().endswith("ç­"):
        base_shift += "ç­" 
    
    class_code = emp_category + region + base_shift
    return class_code

# --------------------
# æ¨¡çµ„ 4ï¼šå»ºç«‹ç­åˆ¥ç¸½è¡¨ (åœ¨æ­¤éšæ®µåŸ·è¡Œè‡ªå‹•å¡«è£œ)
# --------------------
def create_shift_summary(df_analysis: pd.DataFrame) -> pd.DataFrame:
    if df_analysis.empty:
        return pd.DataFrame()
    df_analysis = df_analysis.copy()
    df_analysis["æ—¥æœŸ"] = pd.to_datetime(df_analysis["æ—¥æœŸ"], errors="coerce")
    df_analysis = df_analysis.dropna(subset=["æ—¥æœŸ"])
    all_dates = sorted(df_analysis["æ—¥æœŸ"].dt.strftime("%Y-%m-%d").unique())

    # å»ºç«‹è·ç¨±å°ç…§è¡¨ (ç¢ºä¿æ¯å€‹å“¡å·¥éƒ½æœ‰è·ç¨±)
    emp_title_map = df_analysis[["å“¡å·¥ç·¨è™Ÿ", "å§“å", "è·ç¨±"]].drop_duplicates().set_index(["å“¡å·¥ç·¨è™Ÿ", "å§“å"])["è·ç¨±"].to_dict()

    summary_dict = {}
    for _, row in df_analysis.iterrows():
        emp_id = str(row["å“¡å·¥ç·¨è™Ÿ"])
        emp_name = str(row["å§“å"])
        if not emp_name or emp_name.strip() in ["None", "nan"]:
            continue
        shift_date = row["æ—¥æœŸ"].strftime("%Y-%m-%d")
        class_code = row["ç­åˆ¥ä»£ç¢¼"]
        key = (emp_id, emp_name)
        if key not in summary_dict:
            summary_dict[key] = {}
        summary_dict[key][shift_date] = class_code

    data_out = []
    
    for (emp_id, emp_name), shifts in summary_dict.items():
        title = str(emp_title_map.get((emp_id, emp_name), "")).strip()
        
        # æ’é™¤é‚è¼¯ï¼šè·ç¨±åŒ…å« "é†«å¸«" æˆ– "å…¼è·" è€…ï¼Œä¸è‡ªå‹•å¡«è£œ
        is_excluded = ("é†«å¸«" in title) or ("å…¼è·" in title)
        
        # æº–å‚™å¡«è£œç”¨çš„å¾ªç’°å™¨ï¼š{sta} -> {res} -> {sta} ...
        leave_cycle = cycle(["{sta}", "{res}"])
        
        row = [emp_id, emp_name]
        for d in all_dates:
            # å–å¾—ç•¶å¤©çš„ã€Œè½‰æ›å¾Œç­åˆ¥ä»£ç¢¼ã€
            val = shifts.get(d, "")
            
            # å¦‚æœä»£ç¢¼æ˜¯ç©ºçš„ (ä»£è¡¨ç•¶å¤©ç„¡ç­)ï¼Œä¸”è©²å“¡å·¥æ²’æœ‰è¢«æ’é™¤
            if val == "" and not is_excluded:
                val = next(leave_cycle) # å¡«å…¥å‡åˆ¥
                
            row.append(val)
        data_out.append(row)

    columns = ["å“¡å·¥ç·¨è™Ÿ", "å“¡å·¥å§“å"] + all_dates
    return pd.DataFrame(data_out, columns=columns)

# --------------------
# Streamlit ä¸»ç¨‹å¼
# --------------------
st.set_page_config(page_title="ç­è¡¨è™•ç†å™¨", layout="wide")

st.title("ç­è¡¨è™•ç†å™¨")
st.markdown("""
**åŠŸèƒ½èªªæ˜**ï¼š
1. **ç­åˆ¥è½‰æ›**ï¼šæ”¯æ´ç‰¹æ®Šæ—©ç­èˆ‡å…¨å¤©ç­é‚è¼¯ã€‚
2. **è‡ªå‹•å¡«è£œ**ï¼šç”¢å‡ºç¸½è¡¨æ™‚ï¼Œé‡å°éé†«å¸«/å…¼è·äººå“¡çš„ç©ºç­ï¼Œè‡ªå‹•ä¾åºå¡«å…¥ `{sta}` èˆ‡ `{res}`ã€‚
""")

# ä¸Šå‚³ä»‹é¢
shift_file = st.file_uploader("ğŸ“‚ æ­¥é©Ÿ 1ï¼šä¸Šå‚³ç­è¡¨ Excel", type=["xlsx", "xlsm"])
employee_file = st.file_uploader("ğŸ“‚ æ­¥é©Ÿ 2ï¼šä¸Šå‚³å“¡å·¥è³‡æ–™ Excel", type=["xlsx", "xlsm"])

if shift_file and employee_file:
    wb_shift = load_workbook(shift_file)
    wb_emp = load_workbook(employee_file)

    selectable_sheets = [s for s in wb_shift.sheetnames if s not in ["å½™æ•´çµæœ", "ç­åˆ¥åˆ†æ", "ç­åˆ¥ç¸½è¡¨"]]
    selected_sheets = st.multiselect("æ­¥é©Ÿ 3ï¼šé¸æ“‡è¦è™•ç†çš„ç­è¡¨åˆ†é ", selectable_sheets)
    
    emp_sheet_names = wb_emp.sheetnames
    employee_sheet_name = st.selectbox("æ­¥é©Ÿ 4ï¼šé¸æ“‡å“¡å·¥è³‡æ–™åˆ†é ", emp_sheet_names)

    if st.button("ğŸš€ é–‹å§‹è™•ç†"):
        if not selected_sheets:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹ç­è¡¨åˆ†é ï¼")
        else:
            with st.spinner('è³‡æ–™è™•ç†ä¸­...'):
                df_shift = consolidate_selected_sheets(wb_shift, selected_sheets)
                
                ws_emp = wb_emp[employee_sheet_name]
                data_emp = ws_emp.values
                cols_emp = [str(c).strip() for c in next(data_emp)] # æ¸…æ´—æ¨™é¡Œ
                df_emp = pd.DataFrame(data_emp, columns=cols_emp)

                shift_map = {"æ—©": "æ—©", "åˆ": "åˆ", "æ™š": "æ™š"} 

                # 1. åˆ†æä¸¦è½‰æ›ç­åˆ¥ä»£ç¢¼
                df_analysis = create_shift_analysis(df_shift, df_emp, shift_map)
                
                # 2. è£½ä½œç¸½è¡¨ä¸¦åŸ·è¡Œè‡ªå‹•å¡«è£œ
                df_summary = create_shift_summary(df_analysis)

            st.success("è™•ç†å®Œæˆï¼")
            
            st.subheader("ğŸ“Š ç­åˆ¥ç¸½è¡¨é è¦½ (å«è‡ªå‹•å¡«è£œçµæœ)")
            st.dataframe(df_summary, use_container_width=True)

            # ä¸‹è¼‰æŒ‰éˆ•
            with BytesIO() as output:
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df_summary.to_excel(writer, sheet_name="ç­åˆ¥ç¸½è¡¨", index=False)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ Excel æª”æ¡ˆ",
                    data=output.getvalue(),
                    file_name="ç­åˆ¥ç¸½è¡¨_è‡ªå‹•å¡«è£œ.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )
