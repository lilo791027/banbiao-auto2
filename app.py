import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from io import BytesIO
from datetime import datetime
import re
from itertools import cycle

# --------------------
# æ¨¡çµ„ 1ï¼šè§£é™¤åˆä½µå„²å­˜æ ¼ä¸¦å¡«å…¥åŸå€¼
# --------------------
def unmerge_and_fill(ws):
    for merged in list(ws.merged_cells.ranges):
        value = ws.cell(merged.min_row, merged.min_col).value
        ws.unmerge_cells(str(merged))
        for row in ws[merged.coord]:
            for cell in row:
                cell.value = value

# --------------------
# æ¨¡çµ„ 2ï¼šæ•´ç†ç­è¡¨è³‡æ–™
# --------------------
def consolidate_selected_sheets(wb, sheet_names):
    all_data = []
    for sheet_name in sheet_names:
        ws = wb[sheet_name]
        unmerge_and_fill(ws)
        try:
            clinic_name = str(ws.cell(row=1, column=1).value).strip()[:4]
        except:
            clinic_name = "æœªçŸ¥è¨ºæ‰€"

        max_row = ws.max_row
        max_col = ws.max_column
        
        for r in range(1, max_row + 1):
            for c in range(2, max_col + 1):
                cell_value = ws.cell(r, c).value
                if isinstance(cell_value, datetime):
                    date_val = cell_value
                    i = r + 3
                    while i <= max_row:
                        shift_type = str(ws.cell(i, c).value).strip()
                        if shift_type in ["", "None"] or isinstance(ws.cell(i, c).value, datetime):
                            break
                        
                        if shift_type in ["æ—©", "åˆ", "æ™š"]:
                            i += 1
                            while i <= max_row:
                                cell_v = ws.cell(i, c).value
                                if isinstance(cell_v, datetime):
                                    break
                                val = str(cell_v).strip()
                                if val in ["æ—©", "åˆ", "æ™š"]:
                                    break
                                if val and val not in ["None", "nan", "="]:
                                    all_data.append([
                                        clinic_name,
                                        date_val.strftime("%Y/%m/%d"),
                                        shift_type,
                                        val
                                    ])
                                i += 1
                            i -= 1
                        i += 1
    df = pd.DataFrame(all_data, columns=["è¨ºæ‰€", "æ—¥æœŸ", "ç­åˆ¥", "å§“å"])
    return df

# --------------------
# æ¨¡çµ„ 3ï¼šå»ºç«‹ç­åˆ¥åˆ†æè¡¨ (æ”¹è‰¯ï¼šæ”¯æ´å»é™¤åå­—ç©ºç™½ä»¥å¢åŠ å°æ‡‰æˆåŠŸç‡)
# --------------------
def create_shift_analysis(df_shift: pd.DataFrame, df_emp: pd.DataFrame, shift_map: dict) -> pd.DataFrame:
    df_shift = df_shift.copy()
    df_emp = df_emp.copy()
    
    # æ¸…æ´—æ¬„ä½åç¨± (å»é™¤ç©ºç™½)
    df_shift.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_shift.columns]
    df_emp.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_emp.columns]
    
    # æ¬„ä½å°æ‡‰å‡½å¼
    def get_col_name(df, keywords):
        for col in df.columns:
            for kw in keywords:
                if kw in col: return col
        return None

    col_map = {
        "å§“å": get_col_name(df_emp, ["å§“å"]),
        "ç·¨è™Ÿ": get_col_name(df_emp, ["ç·¨è™Ÿ", "å·¥è™Ÿ"]), 
        "è·ç¨±": get_col_name(df_emp, ["è·ç¨±", "è·å‹™", "è·ä½"]),
        "éƒ¨é–€": get_col_name(df_emp, ["éƒ¨é–€", "å–®ä½"]),
        "åˆ†é¡": get_col_name(df_emp, ["åˆ†é¡", "é¡åˆ¥"]),
        "ç‰¹æ®Šæ—©ç­": get_col_name(df_emp, ["ç‰¹æ®Šæ—©ç­", "ç‰¹æ¬Š"])
    }
    
    # å»ºç«‹å“¡å·¥å­—å…¸ (Key ç‚ºå»é™¤ç©ºç™½å¾Œçš„å§“å)
    emp_dict = {}
    for _, row in df_emp.iterrows():
        name_col = col_map["å§“å"]
        if not name_col: continue

        raw_name = str(row.get(name_col, "")).strip()
        # å¼·åŠ›æ¸…æ´—åå­—ï¼šå»é™¤æ‰€æœ‰ç©ºç™½
        clean_name_key = raw_name.replace(" ", "").replace("ã€€", "")
        
        if clean_name_key and clean_name_key not in ["nan", "None"]:
            emp_dict[clean_name_key] = [
                str(row.get(col_map["ç·¨è™Ÿ"], "")).strip(),
                str(row.get(col_map["éƒ¨é–€"], "")).strip(),
                str(row.get(col_map["è·ç¨±"], "")).strip(),
                str(row.get(col_map["åˆ†é¡"], "")).strip(),
                str(row.get(col_map["ç‰¹æ®Šæ—©ç­"], "")).strip()
            ]

    shift_dict = {}
    for _, row in df_shift.iterrows():
        raw_name = str(row.get("å§“å", "")).strip()
        clean_name_key = raw_name.replace(" ", "").replace("ã€€", "") # åŒæ¨£æ¸…æ´—ç­è¡¨åå­—
        
        clinic = str(row.get("è¨ºæ‰€", "")).strip()
        date_val = row.get("æ—¥æœŸ", "")
        shift_type = str(row.get("ç­åˆ¥", "")).strip()
        
        if not raw_name or pd.isna(date_val): continue
        
        # ä½¿ç”¨æ¸…æ´—å¾Œçš„ key ä¾†å­˜ï¼Œä½†ä¿ç•™åŸå§‹å§“åé¡¯ç¤º
        key = f"{clean_name_key}|{date_val}|{clinic}|{raw_name}"
        if key not in shift_dict: shift_dict[key] = set()
        shift_dict[key].add(shift_type)

    data_out = []
    for key, shifts in shift_dict.items():
        clean_name_key, date_val, clinic, original_name = key.split("|")
        
        # ç”¨æ¸…æ´—éçš„åå­—å»æŸ¥å“¡å·¥è³‡æ–™
        emp_info = emp_dict.get(clean_name_key, ["", "", "", "", ""])
        emp_id, emp_dept, emp_title, emp_category, emp_early_special = emp_info
        
        shift_parts = [s for s in ["æ—©", "åˆ", "æ™š"] if s in shifts]
        shift_type_for_code = "".join(sorted(shift_parts, key=lambda x: {"æ—©": 1, "åˆ": 2, "æ™š": 3}.get(x, 9)))
        
        class_code = get_class_code(emp_category, emp_early_special, clinic, shift_type_for_code, shift_map)
        
        data_out.append([clinic, emp_id, emp_dept, original_name, emp_title, date_val, shift_type_for_code, class_code])

    df_analysis = pd.DataFrame(
        data_out,
        columns=["è¨ºæ‰€", "å“¡å·¥ç·¨è™Ÿ", "æ‰€å±¬éƒ¨é–€", "å§“å", "è·ç¨±", "æ—¥æœŸ", "ç­åˆ¥", "ç­åˆ¥ä»£ç¢¼"]
    )
    
    invalid_names = ["None", "nan", "ç¾©è¨º", "å–®è¨º", "ç›¤é»", "é›»æ‰“", ""]
    df_analysis = df_analysis[~df_analysis["å§“å"].astype(str).str.strip().isin(invalid_names)].copy()
    
    return df_analysis

def get_class_code(emp_category, emp_early_special, clinic_name, shift_type, shift_map):
    region = "ç«‹ä¸" if re.search(r"ç«‹ä¸", str(clinic_name), re.IGNORECASE) else "æ¿åœŸä¸­äº¬"
    is_early_special = str(emp_early_special).strip().lower() in ["æ˜¯", "true", "1", "checked"]

    if is_early_special and "æ—©" in shift_type:
        if shift_type == "æ—©": return "ã€å“¡å·¥ã€‘ç´”æ—©ç­"
        elif shift_type == "æ—©åˆ": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€åˆç­"
        elif shift_type == "æ—©æ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€æ™šç­"
        elif shift_type == "æ—©åˆæ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©åˆæ™šç­"
    
    if shift_type == "æ—©":
        if "é†«å¸«" in emp_category: return "â˜…é†«å¸«â˜…æ—©ç­"
        elif "ä¸»ç®¡" in emp_category: return "â—‡ä¸»ç®¡â—‡æ—©ç­"
        elif "å“¡å·¥" in emp_category: return "ã€å“¡å·¥ã€‘æ—©ç­"

    if shift_type == "æ—©åˆæ™š":
        return f"{emp_category}{region}å…¨å¤©ç­"
    
    base = shift_map.get(shift_type, shift_type)
    if not str(base).strip().endswith("ç­"): base += "ç­"
    return str(emp_category) + str(region) + str(base)

# --------------------
# æ¨¡çµ„ 4ï¼šå»ºç«‹ç­åˆ¥ç¸½è¡¨ (è‡ªå‹•å¡«è£œèˆ‡é™¤éŒ¯)
# --------------------
def create_shift_summary(df_analysis: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    if df_analysis.empty:
        return pd.DataFrame(), pd.DataFrame()
        
    df_analysis = df_analysis.copy()
    df_analysis["æ—¥æœŸ"] = pd.to_datetime(df_analysis["æ—¥æœŸ"], errors="coerce")
    df_analysis = df_analysis.dropna(subset=["æ—¥æœŸ"])
    all_dates = sorted(df_analysis["æ—¥æœŸ"].dt.strftime("%Y-%m-%d").unique())

    # è½‰ç½®è³‡æ–™
    summary_dict = {}
    
    # å¦å¤–å»ºç«‹ä¸€å€‹ Mapping ç”¨ä¾†æŸ¥è·ç¨±å’Œå“¡ç·¨
    info_map = {} 

    for _, row in df_analysis.iterrows():
        emp_id = str(row["å“¡å·¥ç·¨è™Ÿ"]).strip()
        emp_name = str(row["å§“å"]).strip()
        emp_title = str(row["è·ç¨±"]).strip()
        
        shift_date = row["æ—¥æœŸ"].strftime("%Y-%m-%d")
        summary_dict.setdefault((emp_id, emp_name), {})[shift_date] = row["ç­åˆ¥ä»£ç¢¼"]
        
        # è¨˜éŒ„è©²å“¡å·¥çš„è³‡è¨Š (å“¡ç·¨, è·ç¨±) ç”¨æ–¼å¾ŒçºŒåˆ¤æ–·
        info_map[(emp_id, emp_name)] = emp_title

    data_out = []
    debug_list = []

    for (emp_id, emp_name), shifts in summary_dict.items():
        title = info_map.get((emp_id, emp_name), "")
        
        # --- åˆ¤æ–·é‚è¼¯ ---
        # 1. æª¢æŸ¥æ˜¯å¦æœ‰å“¡ç·¨ (éç©ºå€¼)
        has_id = emp_id and emp_id.lower() not in ["nan", "none", ""]
        
        # 2. æª¢æŸ¥æ˜¯å¦ç‚ºæ’é™¤å°è±¡ (é†«å¸« æˆ– å…¼è·)
        is_doctor_or_pt = ("é†«å¸«" in title) or ("å…¼è·" in title)
        
        # 3. ç¶œåˆåˆ¤æ–·ï¼šæœ‰å“¡ç·¨ ä¸” ä¸æ˜¯(é†«å¸«æˆ–å…¼è·) æ‰å¡«è£œ
        should_fill = has_id and (not is_doctor_or_pt)
        
        # 4. è¨˜éŒ„åŸå›  (çµ¦ä½¿ç”¨è€…çœ‹)
        if not has_id:
            reason = "âŒ ç„¡å“¡ç·¨ (åå­—æ²’å°ä¸Š)"
        elif is_doctor_or_pt:
            reason = "âŒ è·ç¨±å«é†«å¸«/å…¼è·"
        else:
            reason = "âœ… ç¬¦åˆå¡«è£œæ¢ä»¶"

        debug_list.append({
            "å§“å": emp_name,
            "å“¡å·¥ç·¨è™Ÿ": emp_id,
            "è·ç¨±": title,
            "å¡«è£œç‹€æ…‹": reason
        })

        leave_cycle = cycle(["{sta}", "{res}"])
        
        row = [emp_id, emp_name]
        for d in all_dates:
            val = shifts.get(d, "")
            
            # å¼·åŠ›ç©ºå€¼åˆ¤æ–·
            is_empty = (val is None) or (str(val).strip() in ["", "nan", "None"])
            
            if is_empty:
                if should_fill:
                    val = next(leave_cycle) 
                else:
                    val = "" 
            
            row.append(val)
        data_out.append(row)

    cols = ["å“¡å·¥ç·¨è™Ÿ", "å“¡å·¥å§“å"] + all_dates
    return pd.DataFrame(data_out, columns=cols), pd.DataFrame(debug_list)

# --------------------
# Streamlit ä¸»ç¨‹å¼
# --------------------
st.set_page_config(page_title="ç­è¡¨è™•ç†å™¨(çµ‚æ¥µä¿®æ­£ç‰ˆ)", layout="wide")
st.title("ç­è¡¨è™•ç†å™¨ (CSV/Excelé€šç”¨ + è‡ªå‹•å»é™¤ç©ºç™½)")
st.info("ğŸ’¡ å¡«è£œè¦å‰‡ï¼šæœ‰ã€å“¡å·¥ç·¨è™Ÿã€‘ä¸”è·ç¨±ä¸å«ã€é†«å¸«/å…¼è·ã€‘çš„å“¡å·¥ï¼Œç©ºç­æœƒè‡ªå‹•å¡«å…¥ `{sta}` / `{res}`ã€‚")

col1, col2 = st.columns(2)
with col1:
    shift_file = st.file_uploader("1. ä¸Šå‚³ç­è¡¨ (Excel)", type=["xlsx", "xlsm"])
with col2:
    # å…è¨±ä¸Šå‚³ csv
    employee_file = st.file_uploader("2. ä¸Šå‚³å“¡å·¥è³‡æ–™ (Excel æˆ– CSV)", type=["xlsx", "xlsm", "csv"])

if shift_file and employee_file:
    # è®€å–ç­è¡¨
    try:
        wb_shift = load_workbook(shift_file, data_only=True)
    except Exception as e:
        st.error(f"ç­è¡¨è®€å–å¤±æ•—: {e}")
        st.stop()
        
    # è®€å–å“¡å·¥è³‡æ–™ (æ”¯æ´ CSV èˆ‡ Excel)
    df_emp_raw = None
    try:
        if employee_file.name.endswith('.csv'):
            # å˜—è©¦ç”¨ pandas è®€å– CSV
            df_emp_raw = pd.read_csv(employee_file)
        else:
            # è®€å– Excel
            wb_emp = load_workbook(employee_file, data_only=True)
            # è®“ä½¿ç”¨è€…é¸å·¥ä½œè¡¨ (å¦‚æœæ˜¯ Excel)
            emp_sheet_name = st.selectbox("é¸æ“‡å“¡å·¥è³‡æ–™å·¥ä½œè¡¨", wb_emp.sheetnames)
            ws = wb_emp[emp_sheet_name]
            data = list(ws.values)
            if data:
                cols = [str(c).strip() for c in data[0]]
                df_emp_raw = pd.DataFrame(data[1:], columns=cols)
    except Exception as e:
        st.error(f"å“¡å·¥è³‡æ–™è®€å–å¤±æ•—: {e}")
        st.stop()

    sheets = [s for s in wb_shift.sheetnames if s not in ["å½™æ•´çµæœ", "ç­åˆ¥åˆ†æ", "ç­åˆ¥ç¸½è¡¨"]]
    selected_sheets = st.multiselect("é¸æ“‡ç­è¡¨å·¥ä½œè¡¨", sheets)

    if st.button("ğŸš€ é–‹å§‹è™•ç†", type="primary"):
        if not selected_sheets:
            st.warning("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹å·¥ä½œè¡¨")
        elif df_emp_raw is None or df_emp_raw.empty:
            st.error("å“¡å·¥è³‡æ–™æ˜¯ç©ºçš„æˆ–è®€å–å¤±æ•—")
        else:
            with st.spinner("è³‡æ–™è™•ç†ä¸­..."):
                df_shift = consolidate_selected_sheets(wb_shift, selected_sheets)
                
                shift_map = {"æ—©": "æ—©", "åˆ": "åˆ", "æ™š": "æ™š"}
                
                df_analysis = create_shift_analysis(df_shift, df_emp_raw, shift_map)
                df_summary, df_debug = create_shift_summary(df_analysis)
            
            st.success("è™•ç†å®Œæˆï¼")
            
            with st.expander("ğŸ•µï¸â€â™€ï¸ èª°æ²’è¢«å¡«è£œï¼Ÿ(é»æ­¤æŸ¥çœ‹åŸå› )", expanded=True):
                st.dataframe(df_debug, use_container_width=True)
                st.caption("è‹¥é¡¯ç¤ºã€ç„¡å“¡ç·¨ã€ï¼Œä»£è¡¨è©²åå­—åœ¨å“¡å·¥è¡¨æ‰¾ä¸åˆ°ï¼ˆè«‹æª¢æŸ¥åå­—æ˜¯å¦æœ‰å·®ç•°ï¼‰ã€‚")

            st.subheader("ğŸ“Š ç­åˆ¥ç¸½è¡¨")
            st.dataframe(df_summary, use_container_width=True)

            with BytesIO() as output:
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df_summary.to_excel(writer, sheet_name="ç­åˆ¥ç¸½è¡¨", index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel çµæœ", output.getvalue(), "ç­åˆ¥ç¸½è¡¨_å®Œæˆç‰ˆ.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
