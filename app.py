import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from io import BytesIO
from datetime import datetime
import re
from itertools import cycle

# --------------------
# æ¨¡çµ„ 1ï¼šè§£é™¤åˆä½µå„²å­˜æ ¼ä¸¦å¡«å…¥åŸå€¼
# --------------------
def unmerge_and_fill(ws):
    for merged in list(ws.merged_cells.ranges):
        value = ws.cell(merged.min_row, merged.min_col).value
        ws.unmerge_cells(str(merged))
        for row in ws[merged.coord]:
            for cell in row:
                cell.value = value

# --------------------
# æ¨¡çµ„ 2ï¼šæ•´ç†ç­è¡¨è³‡æ–™
# --------------------
def consolidate_selected_sheets(wb, sheet_names):
    all_data = []
    for sheet_name in sheet_names:
        ws = wb[sheet_name]
        unmerge_and_fill(ws)
        try:
            clinic_name = str(ws.cell(row=1, column=1).value).strip()[:4]
        except:
            clinic_name = "æœªçŸ¥è¨ºæ‰€"

        max_row = ws.max_row
        max_col = ws.max_column
        
        for r in range(1, max_row + 1):
            for c in range(2, max_col + 1):
                cell_value = ws.cell(r, c).value
                if isinstance(cell_value, datetime):
                    date_val = cell_value
                    i = r + 3
                    while i <= max_row:
                        shift_type = str(ws.cell(i, c).value).strip()
                        if shift_type in ["", "None"] or isinstance(ws.cell(i, c).value, datetime):
                            break
                        
                        if shift_type in ["æ—©", "åˆ", "æ™š"]:
                            i += 1
                            while i <= max_row:
                                cell_v = ws.cell(i, c).value
                                if isinstance(cell_v, datetime):
                                    break
                                val = str(cell_v).strip()
                                if val in ["æ—©", "åˆ", "æ™š"]:
                                    break
                                if val and val not in ["None", "nan", "="]:
                                    all_data.append([
                                        clinic_name,
                                        date_val.strftime("%Y/%m/%d"),
                                        shift_type,
                                        val
                                    ])
                                i += 1
                            i -= 1
                        i += 1
    df = pd.DataFrame(all_data, columns=["è¨ºæ‰€", "æ—¥æœŸ", "ç­åˆ¥", "å§“å"])
    return df

# --------------------
# æ¨¡çµ„ 3ï¼šå»ºç«‹ç­åˆ¥åˆ†æè¡¨
# --------------------
def create_shift_analysis(df_shift: pd.DataFrame, df_emp: pd.DataFrame, shift_map: dict) -> pd.DataFrame:
    df_shift = df_shift.copy()
    df_emp = df_emp.copy()
    
    # æ¸…æ´—æ¬„ä½åç¨±
    df_shift.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_shift.columns]
    df_emp.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_emp.columns]
    
    def get_col_name(df, keywords):
        for col in df.columns:
            for kw in keywords:
                if kw in col: return col
        return None

    col_map = {
        "å§“å": get_col_name(df_emp, ["å§“å"]),
        "ç·¨è™Ÿ": get_col_name(df_emp, ["ç·¨è™Ÿ", "å·¥è™Ÿ"]), # é—œéµï¼šæŠ“å–å“¡ç·¨
        "è·ç¨±": get_col_name(df_emp, ["è·ç¨±", "è·å‹™", "è·ä½"]),
        "éƒ¨é–€": get_col_name(df_emp, ["éƒ¨é–€", "å–®ä½"]),
        "åˆ†é¡": get_col_name(df_emp, ["åˆ†é¡", "é¡åˆ¥"]),
        "ç‰¹æ®Šæ—©ç­": get_col_name(df_emp, ["ç‰¹æ®Šæ—©ç­", "ç‰¹æ¬Š"])
    }
    
    emp_dict = {}
    for _, row in df_emp.iterrows():
        name_col = col_map["å§“å"]
        if not name_col: continue

        name = str(row.get(name_col, "")).strip()
        if name and name not in ["nan", "None"]:
            emp_dict[name] = [
                str(row.get(col_map["ç·¨è™Ÿ"], "")).strip(), # é€™æ˜¯æœ€é‡è¦çš„åˆ¤æ–·ä¾æ“š
                str(row.get(col_map["éƒ¨é–€"], "")).strip(),
                str(row.get(col_map["è·ç¨±"], "")).strip(),
                str(row.get(col_map["åˆ†é¡"], "")).strip(),
                str(row.get(col_map["ç‰¹æ®Šæ—©ç­"], "")).strip()
            ]

    shift_dict = {}
    for _, row in df_shift.iterrows():
        name = str(row.get("å§“å", "")).strip()
        clinic = str(row.get("è¨ºæ‰€", "")).strip()
        date_val = row.get("æ—¥æœŸ", "")
        shift_type = str(row.get("ç­åˆ¥", "")).strip()
        if not name or pd.isna(date_val): continue
        key = f"{name}|{date_val}|{clinic}"
        if key not in shift_dict: shift_dict[key] = set()
        shift_dict[key].add(shift_type)

    data_out = []
    for key, shifts in shift_dict.items():
        name, date_val, clinic = key.split("|")
        emp_info = emp_dict.get(name, ["", "", "", "", ""])
        emp_id, emp_dept, emp_title, emp_category, emp_early_special = emp_info
        
        shift_parts = [s for s in ["æ—©", "åˆ", "æ™š"] if s in shifts]
        shift_type_for_code = "".join(sorted(shift_parts, key=lambda x: {"æ—©": 1, "åˆ": 2, "æ™š": 3}.get(x, 9)))
        
        class_code = get_class_code(emp_category, emp_early_special, clinic, shift_type_for_code, shift_map)
        
        data_out.append([clinic, emp_id, emp_dept, name, emp_title, date_val, shift_type_for_code, class_code])

    df_analysis = pd.DataFrame(
        data_out,
        columns=["è¨ºæ‰€", "å“¡å·¥ç·¨è™Ÿ", "æ‰€å±¬éƒ¨é–€", "å§“å", "è·ç¨±", "æ—¥æœŸ", "ç­åˆ¥", "ç­åˆ¥ä»£ç¢¼"]
    )
    
    invalid_names = ["None", "nan", "ç¾©è¨º", "å–®è¨º", "ç›¤é»", "é›»æ‰“", ""]
    df_analysis = df_analysis[~df_analysis["å§“å"].astype(str).str.strip().isin(invalid_names)].copy()
    
    return df_analysis

def get_class_code(emp_category, emp_early_special, clinic_name, shift_type, shift_map):
    region = "ç«‹ä¸" if re.search(r"ç«‹ä¸", str(clinic_name), re.IGNORECASE) else "æ¿åœŸä¸­äº¬"
    is_early_special = str(emp_early_special).strip().lower() in ["æ˜¯", "true", "1", "checked"]

    if is_early_special and "æ—©" in shift_type:
        if shift_type == "æ—©": return "ã€å“¡å·¥ã€‘ç´”æ—©ç­"
        elif shift_type == "æ—©åˆ": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€åˆç­"
        elif shift_type == "æ—©æ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€æ™šç­"
        elif shift_type == "æ—©åˆæ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©åˆæ™šç­"
    
    if shift_type == "æ—©":
        if "é†«å¸«" in emp_category: return "â˜…é†«å¸«â˜…æ—©ç­"
        elif "ä¸»ç®¡" in emp_category: return "â—‡ä¸»ç®¡â—‡æ—©ç­"
        elif "å“¡å·¥" in emp_category: return "ã€å“¡å·¥ã€‘æ—©ç­"

    if shift_type == "æ—©åˆæ™š":
        return f"{emp_category}{region}å…¨å¤©ç­"
    
    base = shift_map.get(shift_type, shift_type)
    if not str(base).strip().endswith("ç­"): base += "ç­"
    return str(emp_category) + str(region) + str(base)

# --------------------
# æ¨¡çµ„ 4ï¼šå»ºç«‹ç­åˆ¥ç¸½è¡¨ (é‚è¼¯æ›´æ–°ï¼šåªçœ‹å“¡ç·¨)
# --------------------
def create_shift_summary(df_analysis: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    if df_analysis.empty:
        return pd.DataFrame(), pd.DataFrame()
        
    df_analysis = df_analysis.copy()
    df_analysis["æ—¥æœŸ"] = pd.to_datetime(df_analysis["æ—¥æœŸ"], errors="coerce")
    df_analysis = df_analysis.dropna(subset=["æ—¥æœŸ"])
    all_dates = sorted(df_analysis["æ—¥æœŸ"].dt.strftime("%Y-%m-%d").unique())

    # è½‰ç½®è³‡æ–™
    summary_dict = {}
    for _, row in df_analysis.iterrows():
        emp_id = str(row["å“¡å·¥ç·¨è™Ÿ"])
        emp_name = str(row["å§“å"])
        shift_date = row["æ—¥æœŸ"].strftime("%Y-%m-%d")
        summary_dict.setdefault((emp_id, emp_name), {})[shift_date] = row["ç­åˆ¥ä»£ç¢¼"]

    data_out = []
    debug_list = []

    for (emp_id, emp_name), shifts in summary_dict.items():
        # --- åˆ¤æ–·é‚è¼¯æ›´æ–°ï¼šåªæª¢æŸ¥æ˜¯å¦æœ‰å“¡å·¥ç·¨è™Ÿ ---
        clean_id = str(emp_id).strip()
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºæœ‰æ•ˆå“¡ç·¨ (éç©º, éNone, énan)
        has_id = clean_id and clean_id.lower() not in ["nan", "none", ""]
        
        # è‹¥ã€æœ‰å“¡ç·¨ã€‘å‰‡ã€è¦å¡«è£œã€‘(should_fill = True)
        should_fill = has_id
        
        # æ”¶é›†è¨ºæ–·è³‡è¨Š
        debug_list.append({
            "å§“å": emp_name,
            "å“¡å·¥ç·¨è™Ÿ": clean_id if has_id else "(ç„¡)",
            "ç‹€æ…‹": "âœ… è‡ªå‹•å¡«è£œ" if should_fill else "âŒ ä¸å¡«è£œ",
            "åŸå› ": "æœ‰å“¡ç·¨" if should_fill else "ç„¡å“¡ç·¨"
        })

        leave_cycle = cycle(["{sta}", "{res}"])
        
        row = [emp_id, emp_name]
        for d in all_dates:
            val = shifts.get(d, "")
            
            # å¼·åŠ›ç©ºå€¼åˆ¤æ–·
            is_empty = (val is None) or (str(val).strip() in ["", "nan", "None"])
            
            if is_empty:
                if should_fill:
                    val = next(leave_cycle) # æœ‰å“¡ç·¨å°±å¡«
                else:
                    val = "" # æ²’å“¡ç·¨ä¿æŒç©ºç™½
            
            row.append(val)
        data_out.append(row)

    cols = ["å“¡å·¥ç·¨è™Ÿ", "å“¡å·¥å§“å"] + all_dates
    return pd.DataFrame(data_out, columns=cols), pd.DataFrame(debug_list)

# --------------------
# Streamlit ä¸»ç¨‹å¼
# --------------------
st.set_page_config(page_title="ç­è¡¨è™•ç†å™¨(å“¡ç·¨åˆ¤æ–·ç‰ˆ)", layout="wide")
st.title("ç­è¡¨è™•ç†å™¨ (å“¡ç·¨åˆ¤æ–·ç‰ˆ)")
st.info("å¡«è£œè¦å‰‡å·²æ›´æ–°ï¼š**åªæœ‰å…·å‚™ã€Œå“¡å·¥ç·¨è™Ÿã€çš„äººå“¡ï¼Œç©ºç­æ‰æœƒè‡ªå‹•å¡«è£œ**ã€‚")

col1, col2 = st.columns(2)
with col1:
    shift_file = st.file_uploader("1. ä¸Šå‚³ç­è¡¨", type=["xlsx", "xlsm"])
with col2:
    employee_file = st.file_uploader("2. ä¸Šå‚³å“¡å·¥è³‡æ–™", type=["xlsx", "xlsm"])

if shift_file and employee_file:
    try:
        wb_shift = load_workbook(shift_file, data_only=True)
        wb_emp = load_workbook(employee_file, data_only=True)
    except Exception as e:
        st.error(f"æª”æ¡ˆè®€å–å¤±æ•—: {e}")
        st.stop()

    sheets = [s for s in wb_shift.sheetnames if s not in ["å½™æ•´çµæœ", "ç­åˆ¥åˆ†æ", "ç­åˆ¥ç¸½è¡¨"]]
    selected_sheets = st.multiselect("é¸æ“‡ç­è¡¨å·¥ä½œè¡¨", sheets)
    emp_sheet_name = st.selectbox("é¸æ“‡å“¡å·¥è³‡æ–™å·¥ä½œè¡¨", wb_emp.sheetnames)

    if st.button("ğŸš€ é–‹å§‹è™•ç†", type="primary"):
        if not selected_sheets:
            st.warning("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹å·¥ä½œè¡¨")
        else:
            with st.spinner("è³‡æ–™è™•ç†ä¸­..."):
                df_shift = consolidate_selected_sheets(wb_shift, selected_sheets)
                
                ws = wb_emp[emp_sheet_name]
                data = list(ws.values)
                if data:
                    cols = [str(c).strip() for c in data[0]]
                    df_emp = pd.DataFrame(data[1:], columns=cols)
                else:
                    st.error("å“¡å·¥è³‡æ–™è¡¨æ˜¯ç©ºçš„ï¼")
                    st.stop()

                shift_map = {"æ—©": "æ—©", "åˆ": "åˆ", "æ™š": "æ™š"}
                
                df_analysis = create_shift_analysis(df_shift, df_emp, shift_map)
                df_summary, df_debug = create_shift_summary(df_analysis)
            
            st.success("è™•ç†å®Œæˆï¼")
            
            with st.expander("ğŸ•µï¸â€â™€ï¸ è¨ºæ–·å ±å‘Šï¼šæª¢æŸ¥èª°æœ‰å“¡ç·¨ï¼Ÿ(é»æ“Šå±•é–‹)", expanded=True):
                st.dataframe(df_debug, use_container_width=True)

            st.subheader("ğŸ“Š ç­åˆ¥ç¸½è¡¨")
            st.dataframe(df_summary, use_container_width=True)

            with BytesIO() as output:
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df_summary.to_excel(writer, sheet_name="ç­åˆ¥ç¸½è¡¨", index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel çµæœ", output.getvalue(), "ç­åˆ¥ç¸½è¡¨_å“¡ç·¨ç‰ˆ.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
