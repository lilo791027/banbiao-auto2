import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from io import BytesIO
from datetime import datetime
import re
from itertools import cycle

# --------------------
# æ¨¡çµ„ 1ï¼šè§£é™¤åˆä½µå„²å­˜æ ¼ä¸¦å¡«å…¥åŸå€¼
# --------------------
def unmerge_and_fill(ws):
    for merged in list(ws.merged_cells.ranges):
        value = ws.cell(merged.min_row, merged.min_col).value
        ws.unmerge_cells(str(merged))
        for row in ws[merged.coord]:
            for cell in row:
                cell.value = value

# --------------------
# æ¨¡çµ„ 2ï¼šæ•´ç†ç­è¡¨è³‡æ–™
# --------------------
def consolidate_selected_sheets(wb, sheet_names):
    all_data = []
    for sheet_name in sheet_names:
        ws = wb[sheet_name]
        unmerge_and_fill(ws)
        
        # å˜—è©¦è®€å–è¨ºæ‰€åç¨±ï¼Œè‹¥è®€ä¸åˆ°çµ¦é è¨­å€¼
        try:
            clinic_name = str(ws.cell(row=1, column=1).value).strip()[:4]
        except:
            clinic_name = "æœªçŸ¥è¨ºæ‰€"

        max_row = ws.max_row
        max_col = ws.max_column
        
        for r in range(1, max_row + 1):
            for c in range(2, max_col + 1):
                cell_value = ws.cell(r, c).value
                # ç°¡å–®åˆ¤æ–·ï¼šå¦‚æœæ ¼å­æ˜¯æ—¥æœŸæ ¼å¼ï¼Œå¯èƒ½æ˜¯æ—¥æœŸçš„é–‹é ­
                if isinstance(cell_value, datetime):
                    date_val = cell_value
                    i = r + 3
                    while i <= max_row:
                        shift_type = str(ws.cell(i, c).value).strip()
                        
                        # é‚Šç•Œæª¢æŸ¥ï¼šé‡åˆ°ç©ºç™½æˆ–éç­åˆ¥é—œéµå­—åœæ­¢
                        if shift_type in ["", "None"] or isinstance(ws.cell(i, c).value, datetime):
                            break
                        
                        # æŠ“å–ç­åˆ¥ (æ—©/åˆ/æ™š)
                        if shift_type in ["æ—©", "åˆ", "æ™š"]:
                            i += 1
                            while i <= max_row:
                                cell_v = ws.cell(i, c).value
                                if isinstance(cell_v, datetime): # é‡åˆ°ä¸‹ä¸€å€‹æ—¥æœŸå€å¡Š
                                    break
                                
                                val = str(cell_v).strip()
                                if val in ["æ—©", "åˆ", "æ™š"]: # é‡åˆ°ä¸‹ä¸€å€‹ç­åˆ¥
                                    break
                                
                                # æ’é™¤æ˜é¡¯ç„¡æ•ˆçš„å€¼
                                if val and val not in ["None", "nan", "="]:
                                    all_data.append([
                                        clinic_name,
                                        date_val.strftime("%Y/%m/%d"),
                                        shift_type,
                                        val
                                    ])
                                i += 1
                            i -= 1
                        i += 1
    df = pd.DataFrame(all_data, columns=["è¨ºæ‰€", "æ—¥æœŸ", "ç­åˆ¥", "å§“å"])
    return df

# --------------------
# æ¨¡çµ„ 3ï¼šå»ºç«‹ç­åˆ¥åˆ†æè¡¨ (å«å¼·åŒ–çš„æ¬„ä½å°æ‡‰é‚è¼¯)
# --------------------
def create_shift_analysis(df_shift: pd.DataFrame, df_emp: pd.DataFrame, shift_map: dict) -> pd.DataFrame:
    df_shift = df_shift.copy()
    df_emp = df_emp.copy()
    
    # --- æ­¥é©Ÿ A: å¼·åŠ›æ¸…æ´—æ¬„ä½åç¨± (å»é™¤æ‰€æœ‰ç©ºç™½) ---
    # é€™èƒ½è§£æ±º "è· ç¨±" vs "è·ç¨±" çš„å•é¡Œ
    df_shift.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_shift.columns]
    df_emp.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_emp.columns]
    
    # è¼”åŠ©å‡½å¼ï¼šæ¨¡ç³Šæœå°‹æ¬„ä½
    def get_col_name(df, keywords):
        for col in df.columns:
            for kw in keywords:
                if kw in col:
                    return col
        return None

    # --- æ­¥é©Ÿ B: è‡ªå‹•å°‹æ‰¾å°æ‡‰æ¬„ä½ ---
    col_map = {
        "å§“å": get_col_name(df_emp, ["å§“å"]),
        "ç·¨è™Ÿ": get_col_name(df_emp, ["ç·¨è™Ÿ", "å·¥è™Ÿ"]),
        "è·ç¨±": get_col_name(df_emp, ["è·ç¨±", "è·å‹™", "è·ä½"]), # é—œéµï¼šè‡ªå‹•æ‰¾è·ç¨±ç›¸é—œæ¬„ä½
        "éƒ¨é–€": get_col_name(df_emp, ["éƒ¨é–€", "å–®ä½"]),
        "åˆ†é¡": get_col_name(df_emp, ["åˆ†é¡", "é¡åˆ¥"]),
        "ç‰¹æ®Šæ—©ç­": get_col_name(df_emp, ["ç‰¹æ®Šæ—©ç­", "ç‰¹æ¬Š"])
    }
    
    # å»ºç«‹å“¡å·¥å­—å…¸
    emp_dict = {}
    for _, row in df_emp.iterrows():
        name_col = col_map["å§“å"]
        if not name_col: continue # æ²’å§“åæ¬„ä½å°±è·³é

        name = str(row.get(name_col, "")).strip()
        if name and name not in ["nan", "None"]:
            # ä½¿ç”¨ .get(..., "") é˜²æ­¢æ¬„ä½æŠ“ä¸åˆ°å ±éŒ¯
            emp_dict[name] = [
                str(row.get(col_map["ç·¨è™Ÿ"], "")).strip(),
                str(row.get(col_map["éƒ¨é–€"], "")).strip(),
                str(row.get(col_map["è·ç¨±"], "")).strip(), # é€™è£¡æœƒæŠ“åˆ°è·ç¨±
                str(row.get(col_map["åˆ†é¡"], "")).strip(),
                str(row.get(col_map["ç‰¹æ®Šæ—©ç­"], "")).strip()
            ]

    # æ•´ç†ç­è¡¨
    shift_dict = {}
    for _, row in df_shift.iterrows():
        name = str(row.get("å§“å", "")).strip()
        clinic = str(row.get("è¨ºæ‰€", "")).strip()
        date_val = row.get("æ—¥æœŸ", "")
        shift_type = str(row.get("ç­åˆ¥", "")).strip()
        
        if not name or pd.isna(date_val): continue
        key = f"{name}|{date_val}|{clinic}"
        if key not in shift_dict: shift_dict[key] = set()
        shift_dict[key].add(shift_type)

    data_out = []
    for key, shifts in shift_dict.items():
        name, date_val, clinic = key.split("|")
        
        # å³ä½¿æ²’å°æ‡‰åˆ°å“¡å·¥è³‡æ–™ï¼Œä¹Ÿå…ˆé¡¯ç¤ºï¼Œé¿å…è³‡æ–™éºå¤±
        emp_info = emp_dict.get(name, ["", "", "", "", ""])
        emp_id, emp_dept, emp_title, emp_category, emp_early_special = emp_info
        
        shift_parts = [s for s in ["æ—©", "åˆ", "æ™š"] if s in shifts]
        shift_type_for_code = "".join(sorted(shift_parts, key=lambda x: {"æ—©": 1, "åˆ": 2, "æ™š": 3}.get(x, 9)))
        
        class_code = get_class_code(emp_category, emp_early_special, clinic, shift_type_for_code, shift_map)
        
        data_out.append([clinic, emp_id, emp_dept, name, emp_title, date_val, shift_type_for_code, class_code])

    df_analysis = pd.DataFrame(
        data_out,
        columns=["è¨ºæ‰€", "å“¡å·¥ç·¨è™Ÿ", "æ‰€å±¬éƒ¨é–€", "å§“å", "è·ç¨±", "æ—¥æœŸ", "ç­åˆ¥", "ç­åˆ¥ä»£ç¢¼"]
    )
    
    # éæ¿¾ç„¡æ•ˆå§“å
    invalid_names = ["None", "nan", "ç¾©è¨º", "å–®è¨º", "ç›¤é»", "é›»æ‰“", ""]
    df_analysis = df_analysis[~df_analysis["å§“å"].astype(str).str.strip().isin(invalid_names)].copy()
    
    return df_analysis

def get_class_code(emp_category, emp_early_special, clinic_name, shift_type, shift_map):
    region = "ç«‹ä¸" if re.search(r"ç«‹ä¸", str(clinic_name), re.IGNORECASE) else "æ¿åœŸä¸­äº¬"
    is_early_special = str(emp_early_special).strip().lower() in ["æ˜¯", "true", "1", "checked"]

    # 1. ç‰¹æ®Šæ—©ç­
    if is_early_special and "æ—©" in shift_type:
        if shift_type == "æ—©": return "ã€å“¡å·¥ã€‘ç´”æ—©ç­"
        elif shift_type == "æ—©åˆ": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€åˆç­"
        elif shift_type == "æ—©æ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€æ™šç­"
        elif shift_type == "æ—©åˆæ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©åˆæ™šç­"
    
    # 2. ä¸€èˆ¬å–®ä¸€æ—©ç­
    if shift_type == "æ—©":
        if "é†«å¸«" in emp_category: return "â˜…é†«å¸«â˜…æ—©ç­"
        elif "ä¸»ç®¡" in emp_category: return "â—‡ä¸»ç®¡â—‡æ—©ç­"
        elif "å“¡å·¥" in emp_category: return "ã€å“¡å·¥ã€‘æ—©ç­"

    # 3. æ—©åˆæ™š -> å…¨å¤©ç­
    if shift_type == "æ—©åˆæ™š":
        return f"{emp_category}{region}å…¨å¤©ç­"
    
    # 4. å…¶ä»–
    base = shift_map.get(shift_type, shift_type)
    if not str(base).strip().endswith("ç­"): base += "ç­"
    return str(emp_category) + str(region) + str(base)

# --------------------
# æ¨¡çµ„ 4ï¼šå»ºç«‹ç­åˆ¥ç¸½è¡¨ (å«è‡ªå‹•å¡«è£œèˆ‡è¨ºæ–·å ±å‘Š)
# --------------------
def create_shift_summary(df_analysis: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    if df_analysis.empty:
        return pd.DataFrame(), pd.DataFrame()
        
    df_analysis = df_analysis.copy()
    df_analysis["æ—¥æœŸ"] = pd.to_datetime(df_analysis["æ—¥æœŸ"], errors="coerce")
    df_analysis = df_analysis.dropna(subset=["æ—¥æœŸ"])
    all_dates = sorted(df_analysis["æ—¥æœŸ"].dt.strftime("%Y-%m-%d").unique())

    # å»ºç«‹è·ç¨±å°ç…§
    emp_title_map = df_analysis[["å“¡å·¥ç·¨è™Ÿ", "å§“å", "è·ç¨±"]].drop_duplicates().set_index(["å“¡å·¥ç·¨è™Ÿ", "å§“å"])["è·ç¨±"].to_dict()

    # è½‰ç½®è³‡æ–™
    summary_dict = {}
    for _, row in df_analysis.iterrows():
        emp_id = str(row["å“¡å·¥ç·¨è™Ÿ"])
        emp_name = str(row["å§“å"])
        shift_date = row["æ—¥æœŸ"].strftime("%Y-%m-%d")
        summary_dict.setdefault((emp_id, emp_name), {})[shift_date] = row["ç­åˆ¥ä»£ç¢¼"]

    data_out = []
    debug_list = []

    for (emp_id, emp_name), shifts in summary_dict.items():
        # å–å¾—è·ç¨±
        raw_title = emp_title_map.get((emp_id, emp_name), "")
        title_str = str(raw_title).strip()
        
        # æ’é™¤åˆ¤æ–·ï¼šè·ç¨±å« "é†«å¸«" æˆ– "å…¼è·" æˆ– "PT"
        is_excluded = ("é†«å¸«" in title_str) or ("å…¼è·" in title_str) or ("PT" in title_str.upper())
        
        # æ”¶é›†è¨ºæ–·è³‡è¨Š
        debug_list.append({
            "å§“å": emp_name,
            "è®€åˆ°çš„è·ç¨±": title_str if title_str else "(ç©ºç™½-å¯èƒ½æ²’å°æ‡‰åˆ°)",
            "ç‹€æ…‹": "âŒ ä¸å¡«è£œ" if is_excluded else "âœ… è‡ªå‹•å¡«è£œ",
            "åŸå› ": "æ˜¯é†«å¸«/å…¼è·" if is_excluded else "-"
        })

        leave_cycle = cycle(["{sta}", "{res}"])
        
        row = [emp_id, emp_name]
        for d in all_dates:
            val = shifts.get(d, "")
            
            # --- å¼·åŠ›ç©ºå€¼åˆ¤æ–· ---
            # è¦–ç‚ºç©ºç­çš„æƒ…æ³ï¼šNone, nan, ç©ºå­—ä¸²
            is_empty = (val is None) or (str(val).strip() in ["", "nan", "None"])
            
            if is_empty:
                if not is_excluded:
                    val = next(leave_cycle) # å¡«å…¥ä»£ç¢¼
                else:
                    val = "" # ä¿æŒç©ºç™½
            
            row.append(val)
        data_out.append(row)

    cols = ["å“¡å·¥ç·¨è™Ÿ", "å“¡å·¥å§“å"] + all_dates
    return pd.DataFrame(data_out, columns=cols), pd.DataFrame(debug_list)

# --------------------
# Streamlit ä¸»ç¨‹å¼
# --------------------
st.set_page_config(page_title="ç­è¡¨è™•ç†å™¨(å¼·åŠ›ç‰ˆ)", layout="wide")
st.title("ç­è¡¨è™•ç†å™¨ (å¼·åŠ›å®¹éŒ¯ç‰ˆ)")
st.info("æ­¤ç‰ˆæœ¬æœƒè‡ªå‹•ä¿®æ­£ Excel æ¬„ä½åç¨±å·®ç•°ï¼Œä¸¦æä¾›è©³ç´°çš„å¡«è£œè¨ºæ–·ã€‚")

# æª”æ¡ˆä¸Šå‚³
col1, col2 = st.columns(2)
with col1:
    shift_file = st.file_uploader("1. ä¸Šå‚³ç­è¡¨ (xlsx/xlsm)", type=["xlsx", "xlsm"])
with col2:
    employee_file = st.file_uploader("2. ä¸Šå‚³å“¡å·¥è³‡æ–™ (xlsx/xlsm)", type=["xlsx", "xlsm"])

if shift_file and employee_file:
    # ä½¿ç”¨ data_only=True è®€å– Excel è¨ˆç®—å¾Œçš„å€¼ï¼Œé¿å…è®€åˆ°å…¬å¼
    try:
        wb_shift = load_workbook(shift_file, data_only=True)
        wb_emp = load_workbook(employee_file, data_only=True)
    except Exception as e:
        st.error(f"æª”æ¡ˆè®€å–å¤±æ•—ï¼Œè«‹ç¢ºèªæª”æ¡ˆæœªææ¯€: {e}")
        st.stop()

    sheets = [s for s in wb_shift.sheetnames if s not in ["å½™æ•´çµæœ", "ç­åˆ¥åˆ†æ", "ç­åˆ¥ç¸½è¡¨"]]
    selected_sheets = st.multiselect("é¸æ“‡ç­è¡¨å·¥ä½œè¡¨", sheets)
    emp_sheet_name = st.selectbox("é¸æ“‡å“¡å·¥è³‡æ–™å·¥ä½œè¡¨", wb_emp.sheetnames)

    if st.button("ğŸš€ é–‹å§‹è™•ç†", type="primary"):
        if not selected_sheets:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹ç­è¡¨ï¼")
        else:
            with st.spinner("è³‡æ–™è™•ç†ä¸­..."):
                # 1. è™•ç†ç­è¡¨
                df_shift = consolidate_selected_sheets(wb_shift, selected_sheets)
                
                # 2. è™•ç†å“¡å·¥è³‡æ–™ (è½‰æˆ DataFrame)
                ws = wb_emp[emp_sheet_name]
                data = list(ws.values)
                if data:
                    cols = [str(c).strip() for c in data[0]]
                    df_emp = pd.DataFrame(data[1:], columns=cols)
                else:
                    st.error("å“¡å·¥è³‡æ–™è¡¨æ˜¯ç©ºçš„ï¼")
                    st.stop()

                shift_map = {"æ—©": "æ—©", "åˆ": "åˆ", "æ™š": "æ™š"}
                
                # 3. åˆ†æ
                df_analysis = create_shift_analysis(df_shift, df_emp, shift_map)
                
                # 4. ç¸½è¡¨ (å«å¡«è£œ)
                df_summary, df_debug = create_shift_summary(df_analysis)
            
            st.success("è™•ç†å®Œæˆï¼")
            
            # --- é¡¯ç¤ºè¨ºæ–·å ±å‘Š (é—œéµåŠŸèƒ½) ---
            with st.expander("ğŸ•µï¸â€â™€ï¸ è¨ºæ–·å ±å‘Šï¼šæª¢æŸ¥èª°è¢«è‡ªå‹•å¡«è£œäº†ï¼Ÿ(é»æ“Šå±•é–‹)", expanded=True):
                st.dataframe(df_debug, use_container_width=True)
                st.caption("èªªæ˜ï¼šè‹¥ã€è®€åˆ°çš„è·ç¨±ã€‘ç‚ºç©ºç™½ï¼Œä»£è¡¨ Excel æ¬„ä½å°æ‡‰å¤±æ•—ï¼›è‹¥ç‹€æ…‹ç‚ºã€ä¸å¡«è£œã€‘ï¼Œä»£è¡¨ç³»çµ±åˆ¤å®šè©²å“¡ç‚ºé†«å¸«æˆ–å…¼è·ã€‚")

            st.subheader("ğŸ“Š ç­åˆ¥ç¸½è¡¨")
            st.dataframe(df_summary, use_container_width=True)

            # ä¸‹è¼‰
            with BytesIO() as output:
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df_summary.to_excel(writer, sheet_name="ç­åˆ¥ç¸½è¡¨", index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel çµæœ", output.getvalue(), "ç­åˆ¥ç¸½è¡¨_å®Œæ•´ç‰ˆ.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
