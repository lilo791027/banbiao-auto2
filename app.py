import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from io import BytesIO
from datetime import datetime
import re
from itertools import cycle

# --------------------
# æ¨¡çµ„ 1ï¼šè§£é™¤åˆä½µå„²å­˜æ ¼ä¸¦å¡«å…¥åŸå€¼
# --------------------
def unmerge_and_fill(ws):
    for merged in list(ws.merged_cells.ranges):
        value = ws.cell(merged.min_row, merged.min_col).value
        ws.unmerge_cells(str(merged))
        for row in ws[merged.coord]:
            for cell in row:
                cell.value = value

# --------------------
# æ¨¡çµ„ 2ï¼šæ•´ç†ç­è¡¨è³‡æ–™
# --------------------
def consolidate_selected_sheets(wb, sheet_names):
    all_data = []
    for sheet_name in sheet_names:
        ws = wb[sheet_name]
        unmerge_and_fill(ws)
        try:
            clinic_name = str(ws.cell(row=1, column=1).value).strip()[:4]
        except:
            clinic_name = "æœªçŸ¥è¨ºæ‰€"

        max_row = ws.max_row
        max_col = ws.max_column
        
        for r in range(1, max_row + 1):
            for c in range(2, max_col + 1):
                cell_value = ws.cell(r, c).value
                if isinstance(cell_value, datetime):
                    date_val = cell_value
                    i = r + 3
                    while i <= max_row:
                        shift_type = str(ws.cell(i, c).value).strip()
                        if shift_type in ["", "None"] or isinstance(ws.cell(i, c).value, datetime):
                            break
                        
                        if shift_type in ["æ—©", "åˆ", "æ™š"]:
                            i += 1
                            while i <= max_row:
                                cell_v = ws.cell(i, c).value
                                if isinstance(cell_v, datetime):
                                    break
                                val = str(cell_v).strip()
                                if val in ["æ—©", "åˆ", "æ™š"]:
                                    break
                                if val and val not in ["None", "nan", "="]:
                                    all_data.append([
                                        clinic_name,
                                        date_val.strftime("%Y/%m/%d"),
                                        shift_type,
                                        val
                                    ])
                                i += 1
                            i -= 1
                        i += 1
    df = pd.DataFrame(all_data, columns=["è¨ºæ‰€", "æ—¥æœŸ", "ç­åˆ¥", "å§“å"])
    return df

# --------------------
# æ¨¡çµ„ 3ï¼šå»ºç«‹ç­åˆ¥åˆ†æè¡¨
# --------------------
def create_shift_analysis(df_shift: pd.DataFrame, df_emp: pd.DataFrame, shift_map: dict) -> pd.DataFrame:
    df_shift = df_shift.copy()
    df_emp = df_emp.copy()
    
    # æ¸…æ´—æ¬„ä½åç¨±
    df_shift.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_shift.columns]
    df_emp.columns = [str(c).replace(" ", "").replace("ã€€", "").strip() for c in df_emp.columns]
    
    def get_col_name(df, keywords):
        for col in df.columns:
            for kw in keywords:
                if kw in col: return col
        return None

    col_map = {
        "å§“å": get_col_name(df_emp, ["å§“å"]),
        "ç·¨è™Ÿ": get_col_name(df_emp, ["ç·¨è™Ÿ", "å·¥è™Ÿ"]), 
        "è·ç¨±": get_col_name(df_emp, ["è·ç¨±", "è·å‹™", "è·ä½"]),
        "éƒ¨é–€": get_col_name(df_emp, ["éƒ¨é–€", "å–®ä½"]),
        "åˆ†é¡": get_col_name(df_emp, ["åˆ†é¡", "é¡åˆ¥"]),
        "ç‰¹æ®Šæ—©ç­": get_col_name(df_emp, ["ç‰¹æ®Šæ—©ç­", "ç‰¹æ¬Š"])
    }
    
    emp_dict = {}
    for _, row in df_emp.iterrows():
        name_col = col_map["å§“å"]
        if not name_col: continue

        raw_name = str(row.get(name_col, "")).strip()
        clean_name_key = raw_name.replace(" ", "").replace("ã€€", "")
        
        if clean_name_key and clean_name_key not in ["nan", "None"]:
            emp_dict[clean_name_key] = [
                str(row.get(col_map["ç·¨è™Ÿ"], "")).strip(),
                str(row.get(col_map["éƒ¨é–€"], "")).strip(),
                str(row.get(col_map["è·ç¨±"], "")).strip(),
                str(row.get(col_map["åˆ†é¡"], "")).strip(),
                str(row.get(col_map["ç‰¹æ®Šæ—©ç­"], "")).strip()
            ]

    shift_dict = {}
    for _, row in df_shift.iterrows():
        raw_name = str(row.get("å§“å", "")).strip()
        clean_name_key = raw_name.replace(" ", "").replace("ã€€", "")
        
        clinic = str(row.get("è¨ºæ‰€", "")).strip()
        date_val = row.get("æ—¥æœŸ", "")
        shift_type = str(row.get("ç­åˆ¥", "")).strip()
        
        if not raw_name or pd.isna(date_val): continue
        
        key = f"{clean_name_key}|{date_val}|{clinic}|{raw_name}"
        if key not in shift_dict: shift_dict[key] = set()
        shift_dict[key].add(shift_type)

    data_out = []
    for key, shifts in shift_dict.items():
        clean_name_key, date_val, clinic, original_name = key.split("|")
        
        emp_info = emp_dict.get(clean_name_key, ["", "", "", "", ""])
        emp_id, emp_dept, emp_title, emp_category, emp_early_special = emp_info
        
        shift_parts = [s for s in ["æ—©", "åˆ", "æ™š"] if s in shifts]
        shift_type_for_code = "".join(sorted(shift_parts, key=lambda x: {"æ—©": 1, "åˆ": 2, "æ™š": 3}.get(x, 9)))
        
        class_code = get_class_code(emp_category, emp_early_special, clinic, shift_type_for_code, shift_map)
        
        data_out.append([clinic, emp_id, emp_dept, original_name, emp_title, date_val, shift_type_for_code, class_code])

    df_analysis = pd.DataFrame(
        data_out,
        columns=["è¨ºæ‰€", "å“¡å·¥ç·¨è™Ÿ", "æ‰€å±¬éƒ¨é–€", "å§“å", "è·ç¨±", "æ—¥æœŸ", "ç­åˆ¥", "ç­åˆ¥ä»£ç¢¼"]
    )
    return df_analysis

def get_class_code(emp_category, emp_early_special, clinic_name, shift_type, shift_map):
    region = "ç«‹ä¸" if re.search(r"ç«‹ä¸", str(clinic_name), re.IGNORECASE) else "æ¿åœŸä¸­äº¬"
    is_early_special = str(emp_early_special).strip().lower() in ["æ˜¯", "true", "1", "checked"]

    if is_early_special and "æ—©" in shift_type:
        if shift_type == "æ—©": return "ã€å“¡å·¥ã€‘ç´”æ—©ç­"
        elif shift_type == "æ—©åˆ": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€åˆç­"
        elif shift_type == "æ—©æ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©ã€æ™šç­"
        elif shift_type == "æ—©åˆæ™š": return f"ã€å“¡å·¥ã€‘{region}ç´”æ—©åˆæ™šç­"
    
    if shift_type == "æ—©":
        if "é†«å¸«" in emp_category: return "â˜…é†«å¸«â˜…æ—©ç­"
        elif "ä¸»ç®¡" in emp_category: return "â—‡ä¸»ç®¡â—‡æ—©ç­"
        elif "å“¡å·¥" in emp_category: return "ã€å“¡å·¥ã€‘æ—©ç­"

    if shift_type == "æ—©åˆæ™š":
        return f"{emp_category}{region}å…¨å¤©ç­"
    
    base = shift_map.get(shift_type, shift_type)
    if not str(base).strip().endswith("ç­"): base += "ç­"
    return str(emp_category) + str(region) + str(base)

# --------------------
# æ¨¡çµ„ 4ï¼šå»ºç«‹ç­åˆ¥ç¸½è¡¨ (åš´æ ¼éæ¿¾ç‰ˆ)
# --------------------
def create_shift_summary(df_analysis: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    if df_analysis.empty:
        return pd.DataFrame(), pd.DataFrame()
        
    df_analysis = df_analysis.copy()
    df_analysis["æ—¥æœŸ"] = pd.to_datetime(df_analysis["æ—¥æœŸ"], errors="coerce")
    df_analysis = df_analysis.dropna(subset=["æ—¥æœŸ"])
    all_dates = sorted(df_analysis["æ—¥æœŸ"].dt.strftime("%Y-%m-%d").unique())

    # å»ºç«‹ç¸½è¡¨å­—å…¸
    summary_dict = {}
    info_map = {} 

    for _, row in df_analysis.iterrows():
        emp_id = str(row["å“¡å·¥ç·¨è™Ÿ"]).strip()
        emp_name = str(row["å§“å"]).strip()
        emp_title = str(row["è·ç¨±"]).strip()
        
        shift_date = row["æ—¥æœŸ"].strftime("%Y-%m-%d")
        summary_dict.setdefault((emp_id, emp_name), {})[shift_date] = row["ç­åˆ¥ä»£ç¢¼"]
        info_map[(emp_id, emp_name)] = emp_title

    data_out = []
    debug_list = []

    # åƒåœ¾é—œéµå­—æ¸…å–® (å¦‚æœåå­—åŒ…å«é€™äº›ï¼Œç›´æ¥å‰”é™¤)
    invalid_keywords = ["ç¾©è¨º", "å–®è¨º", "ç›¤é»", "é›»æ‰“", "å…¬å‹™", "æ¸¬è©¦"]

    for (emp_id, emp_name), shifts in summary_dict.items():
        title = info_map.get((emp_id, emp_name), "")
        
        # --- 1. åš´æ ¼éæ¿¾ï¼šç„¡å“¡ç·¨æˆ–ç„¡æ•ˆåå­—ç›´æ¥è·³é ---
        has_id = emp_id and emp_id.lower() not in ["nan", "none", ""]
        is_invalid_name = any(k in emp_name for k in invalid_keywords)
        
        if not has_id or is_invalid_name:
            # é€™äº›äººç›´æ¥ä¸åŠ å…¥ data_outï¼Œä¹Ÿä¸é¡¯ç¤ºåœ¨çµæœä¸­
            continue 
        
        # --- 2. åˆ¤æ–·å¡«è£œé‚è¼¯ ---
        is_doctor_or_pt = ("é†«å¸«" in title) or ("å…¼è·" in title)
        
        # æœ‰å“¡ç·¨ ä¸” ä¸æ˜¯(é†«å¸«æˆ–å…¼è·) æ‰å¡«è£œ
        should_fill = not is_doctor_or_pt
        
        # æº–å‚™å¾ªç’°å¡«è£œå™¨
        leave_cycle = cycle(["{sta}", "{res}"])
        
        row = [emp_id, emp_name]
        for d in all_dates:
            val = shifts.get(d, "")
            is_empty = (val is None) or (str(val).strip() in ["", "nan", "None"])
            
            if is_empty:
                if should_fill:
                    val = next(leave_cycle) 
                else:
                    val = "" 
            
            row.append(val)
        data_out.append(row)

    cols = ["å“¡å·¥ç·¨è™Ÿ", "å“¡å·¥å§“å"] + all_dates
    return pd.DataFrame(data_out, columns=cols), pd.DataFrame(debug_list)

# --------------------
# Streamlit ä¸»ç¨‹å¼
# --------------------
st.set_page_config(page_title="ç­è¡¨è™•ç†å™¨(ä¹¾æ·¨ç‰ˆ)", layout="wide")
st.title("ç­è¡¨è™•ç†å™¨ (å·²éæ¿¾ç„¡å“¡ç·¨/ç„¡æ•ˆåå–®)")

col1, col2 = st.columns(2)
with col1:
    shift_file = st.file_uploader("1. ä¸Šå‚³ç­è¡¨ (Excel)", type=["xlsx", "xlsm"])
with col2:
    employee_file = st.file_uploader("2. ä¸Šå‚³å“¡å·¥è³‡æ–™ (Excel æˆ– CSV)", type=["xlsx", "xlsm", "csv"])

if shift_file and employee_file:
    try:
        wb_shift = load_workbook(shift_file, data_only=True)
    except Exception as e:
        st.error(f"ç­è¡¨è®€å–å¤±æ•—: {e}")
        st.stop()
        
    df_emp_raw = None
    try:
        if employee_file.name.endswith('.csv'):
            df_emp_raw = pd.read_csv(employee_file)
        else:
            wb_emp = load_workbook(employee_file, data_only=True)
            emp_sheet_name = st.selectbox("é¸æ“‡å“¡å·¥è³‡æ–™å·¥ä½œè¡¨", wb_emp.sheetnames)
            ws = wb_emp[emp_sheet_name]
            data = list(ws.values)
            if data:
                cols = [str(c).strip() for c in data[0]]
                df_emp_raw = pd.DataFrame(data[1:], columns=cols)
    except Exception as e:
        st.error(f"å“¡å·¥è³‡æ–™è®€å–å¤±æ•—: {e}")
        st.stop()

    sheets = [s for s in wb_shift.sheetnames if s not in ["å½™æ•´çµæœ", "ç­åˆ¥åˆ†æ", "ç­åˆ¥ç¸½è¡¨"]]
    selected_sheets = st.multiselect("é¸æ“‡ç­è¡¨å·¥ä½œè¡¨", sheets)

    if st.button("ğŸš€ é–‹å§‹è™•ç†", type="primary"):
        if not selected_sheets:
            st.warning("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹å·¥ä½œè¡¨")
        elif df_emp_raw is None or df_emp_raw.empty:
            st.error("å“¡å·¥è³‡æ–™æ˜¯ç©ºçš„")
        else:
            with st.spinner("è³‡æ–™è™•ç†ä¸­..."):
                df_shift = consolidate_selected_sheets(wb_shift, selected_sheets)
                shift_map = {"æ—©": "æ—©", "åˆ": "åˆ", "æ™š": "æ™š"}
                
                df_analysis = create_shift_analysis(df_shift, df_emp_raw, shift_map)
                df_summary, _ = create_shift_summary(df_analysis)
            
            st.success("è™•ç†å®Œæˆï¼ç„¡å“¡ç·¨æˆ–ç„¡æ•ˆåå­—å·²è‡ªå‹•å‰”é™¤ã€‚")
            
            st.subheader("ğŸ“Š ç­åˆ¥ç¸½è¡¨ (ä¹¾æ·¨ç‰ˆ)")
            st.dataframe(df_summary, use_container_width=True)

            with BytesIO() as output:
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df_summary.to_excel(writer, sheet_name="ç­åˆ¥ç¸½è¡¨", index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel çµæœ", output.getvalue(), "ç­åˆ¥ç¸½è¡¨_ä¹¾æ·¨ç‰ˆ.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
